{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport timm\nfrom torchvision import transforms\nimport pickle\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom glob import glob\nfrom torch import nn\nfrom PIL import Image\nfrom pathlib import Path\nfrom transformers import AutoModel, AutoProcessor\nimport cv2\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport timm\n\nBATCHSIZE=128\nSAVE_OPT_CKP = True\nSAVE_MODEL_CKP = True\nUNFREEZE_START = 18 # set it to lower number when significantly more samples are included.\n\ntorch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\ntorch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n\nrun_name = f'open-clip224-l14'\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-10T11:52:51.774721Z","iopub.execute_input":"2023-04-10T11:52:51.775550Z","iopub.status.idle":"2023-04-10T11:53:05.754068Z","shell.execute_reply.started":"2023-04-10T11:52:51.775515Z","shell.execute_reply":"2023-04-10T11:53:05.752835Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"# class CFG:\n#     model_path = '/kaggle/input/1742swin/swinv2_large_window12to16_192to256_22kft1k-epoch-2.pth'#\n#     model_name = 'swinv2_large_window12to16_192to256_22kft1k'\n#     input_size = 256\n#     batch_size = 32","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:08:13.711927Z","iopub.execute_input":"2023-04-09T06:08:13.712317Z","iopub.status.idle":"2023-04-09T06:08:13.730121Z","shell.execute_reply.started":"2023-04-09T06:08:13.712279Z","shell.execute_reply":"2023-04-09T06:08:13.728789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# class DiffusionTestDataset(Dataset):\n#     def __init__(self, images, transform):\n#         self.images = images\n#         self.transform = transform\n    \n#     def __len__(self):\n#         return len(self.images)\n\n#     def __getitem__(self, idx):\n#         image = Image.open(self.images[idx])\n#         image = self.transform(image)\n#         return image","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:08:13.731671Z","iopub.execute_input":"2023-04-09T06:08:13.732027Z","iopub.status.idle":"2023-04-09T06:08:13.739802Z","shell.execute_reply.started":"2023-04-09T06:08:13.731991Z","shell.execute_reply":"2023-04-09T06:08:13.738791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# def predict(\n#     images,\n#     model_path,\n#     model_name,\n#     input_size,\n#     batch_size\n# ):\n#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#     transform = transforms.Compose([\n#         transforms.Resize(input_size),\n#         transforms.RandomHorizontalFlip(p=0.5),\n# #         transforms.RandomRotation(degrees=10),\n\n#         #transforms.RandomVerticalFlip(p=0.5),\n#         transforms.ToTensor(),\n#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n#     ])\n#     dataset = DiffusionTestDataset(images, transform)\n#     dataloader = DataLoader(\n#         dataset=dataset,\n#         shuffle=False,\n#         batch_size=batch_size,\n#         pin_memory=True,\n#         num_workers=2,\n#         drop_last=False\n#     )\n\n#     model = timm.create_model(\n#         model_name,\n#         pretrained=False,\n#         num_classes=384\n#     )\n# #     state_dict = torch.load(model_path)\n#     #model.load_state_dict(state_dict，map_=device)\n#     weights = torch.load(model_path)\n#     model.load_state_dict(weights)\n#     model.to(device)\n#     model.eval()\n    \n#     tta_preds = None\n#     for _ in range(3):     #预测两次取平均值\n#         preds = []\n#         for X in tqdm(dataloader, leave=False):\n#             X = X.to(device)\n\n#             with torch.no_grad():\n#                 X_out = model(X)\n#                 preds.append(X_out.cpu().numpy())\n                \n#         if tta_preds is None:\n#             tta_preds = np.vstack(preds).flatten()    #按行组合\n#         else:\n#             tta_preds += np.vstack(preds).flatten()\n    \n#     return tta_preds / 3","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:08:13.741386Z","iopub.execute_input":"2023-04-09T06:08:13.741767Z","iopub.status.idle":"2023-04-09T06:08:13.750548Z","shell.execute_reply.started":"2023-04-09T06:08:13.741732Z","shell.execute_reply":"2023-04-09T06:08:13.749512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# images = list(Path('/kaggle/input/stable-diffusion-image-to-prompts/images').glob('*.png'))\n# imgIds = [i.stem for i in images]\n# EMBEDDING_LENGTH = 384\n# imgId_eId = [\n#     '_'.join(map(str, i)) for i in zip(\n#         np.repeat(imgIds, EMBEDDING_LENGTH),\n#         np.tile(range(EMBEDDING_LENGTH), len(imgIds)))]\n\n# prompt_embeddings = predict(images, CFG.model_path, CFG.model_name, CFG.input_size, CFG.batch_size)\n# submission = pd.DataFrame(\n#     index=imgId_eId,\n#     data=prompt_embeddings,\n#     columns=['val']\n# ).rename_axis('imgId_eId')\n# submission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:08:13.754973Z","iopub.execute_input":"2023-04-09T06:08:13.755332Z","iopub.status.idle":"2023-04-09T06:08:13.765152Z","shell.execute_reply.started":"2023-04-09T06:08:13.755303Z","shell.execute_reply":"2023-04-09T06:08:13.764032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wheels_path = \"/kaggle/input/open-clip-wheels/open_clip_wheels\"\nopen_clip_whl_path = f\"{wheels_path}/open_clip_torch-2.14.0-py3-none-any.whl\"\n!pip install --no-index --find-links $wheels_path $open_clip_whl_path -q\nimport open_clip","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:08:13.766514Z","iopub.execute_input":"2023-04-09T06:08:13.767038Z","iopub.status.idle":"2023-04-09T06:08:23.808293Z","shell.execute_reply.started":"2023-04-09T06:08:13.766938Z","shell.execute_reply":"2023-04-09T06:08:23.806967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_7 = \"/kaggle/input/stable-diffusion-image-to-prompts/images\"\n# sd2 = '/kaggle/input/gustavosta-stable-diffusion-prompts-sd2-v2/eval_images'\npath = sample_7","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:08:23.810405Z","iopub.execute_input":"2023-04-09T06:08:23.811186Z","iopub.status.idle":"2023-04-09T06:08:23.817141Z","shell.execute_reply.started":"2023-04-09T06:08:23.81114Z","shell.execute_reply":"2023-04-09T06:08:23.815939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DiffusionTestDataset(Dataset):\n    def __init__(self, images, transform, input_size):\n        self.images = images\n        self.transform = transform\n        self.size = input_size\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.images[idx])\n        image.resize((self.size, self.size))\n        image = self.transform(image)\n        return image","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:08:23.818572Z","iopub.execute_input":"2023-04-09T06:08:23.819062Z","iopub.status.idle":"2023-04-09T06:08:23.827149Z","shell.execute_reply.started":"2023-04-09T06:08:23.81902Z","shell.execute_reply":"2023-04-09T06:08:23.826081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, model):\n        super(Net, self).__init__()\n        clip = model\n        self.vision = clip.visual\n        self.fc = nn.Linear(768, 384)\n\n    def forward(self, x):\n        out = self.vision(x)\n        return self.fc(out)\n\ndef predict(\n    images,\n    model_path,\n    model_name,\n    input_size,\n    batch_size,\n    open_clip_model=False,\n):\n    \n    if not open_clip_model:\n        model = timm.create_model(\n            model_name,\n            pretrained=False,\n            num_classes=384\n        )\n        transform = transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ])\n    else:\n        model, _, preprocess = open_clip.create_model_and_transforms(model_name)\n        model = Net(model)\n        transform = preprocess\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    dataset = DiffusionTestDataset(images, transform, input_size)\n    dataloader = DataLoader(\n        dataset=dataset,\n        shuffle=False,\n        batch_size=batch_size,\n        pin_memory=True,\n        num_workers=2,\n        drop_last=False\n    )\n    \n    #MLP = \n    state_dict = torch.load(model_path, map_location='cuda:0')\n    model.load_state_dict(state_dict)\n    model.to(device)\n    model.eval()\n    \n    preds = []\n    for X in tqdm(dataloader, leave=False):\n        X = X.to(device)\n\n        with torch.no_grad():\n            X_out = model(X)\n            preds.append(X_out.cpu().numpy())\n    \n    return np.vstack(preds).flatten()","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:11:43.803888Z","iopub.execute_input":"2023-04-09T06:11:43.804441Z","iopub.status.idle":"2023-04-09T06:11:43.820505Z","shell.execute_reply.started":"2023-04-09T06:11:43.804401Z","shell.execute_reply":"2023-04-09T06:11:43.819449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    model_path = '/kaggle/input/one111/60w_convnextl_one-11.pt'\n    model_name = 'convnext_large_d'\n    model_path1 = '/kaggle/input/20alll/60w_again_hard1_sgd-19.pt'\n    model_name1 = 'ViT-L-14'\n    model_path3 = '/kaggle/input/1742swin/swinv2_large_window12to16_192to256_22kft1k-epoch-2.pth'#\n    model_name3 = 'swinv2_large_window12to16_192to256_22kft1k'\n    input_size = 224\n    batch_size = 64\n    input_size1 = 256\n    batch_size1 = 32\nimages = list(Path(path).glob('*.jpg'))\nimages.extend(list(Path(path).glob('*.png')))\nimages = sorted(images)\nprompt_embeddings_clip_vitL = predict(images, CFG.model_path, CFG.model_name, CFG.input_size, CFG.batch_size, open_clip_model=True)\nprompt_embeddings_clip_vitL2 = predict(images, model_path=CFG.model_path3, model_name=CFG.model_name3 , input_size=CFG.input_size1, batch_size=CFG.batch_size1)\nprompt_embeddings_clip_vitL1 = predict(images, model_path=CFG.model_path1, model_name=CFG.model_name1 , input_size=CFG.input_size, batch_size=CFG.batch_size, open_clip_model=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:11:48.672777Z","iopub.execute_input":"2023-04-09T06:11:48.673714Z","iopub.status.idle":"2023-04-09T06:12:31.389977Z","shell.execute_reply.started":"2023-04-09T06:11:48.673646Z","shell.execute_reply":"2023-04-09T06:12:31.38886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt_embeddings = prompt_embeddings_clip_vitL*0.25+prompt_embeddings_clip_vitL1*0.55+prompt_embeddings_clip_vitL2*0.2","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:12:38.047563Z","iopub.execute_input":"2023-04-09T06:12:38.0483Z","iopub.status.idle":"2023-04-09T06:12:38.054081Z","shell.execute_reply.started":"2023-04-09T06:12:38.048259Z","shell.execute_reply":"2023-04-09T06:12:38.052725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimgIds = [i.stem for i in images]\nEMBEDDING_LENGTH = 384\nimgId_eId = [\n    '_'.join(map(str, i)) for i in zip(\n        np.repeat(imgIds, EMBEDDING_LENGTH),\n        np.tile(range(EMBEDDING_LENGTH), len(imgIds)))]\n\nsubmission = pd.DataFrame(\n    index=imgId_eId,\n    data=prompt_embeddings,\n    columns=['val']\n).rename_axis('imgId_eId')\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:12:40.27064Z","iopub.execute_input":"2023-04-09T06:12:40.271389Z","iopub.status.idle":"2023-04-09T06:12:40.313491Z","shell.execute_reply.started":"2023-04-09T06:12:40.27133Z","shell.execute_reply":"2023-04-09T06:12:40.312437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import sys\n# sys.path.append('../input/sentence-transformers-222/sentence-transformers')\n# from sentence_transformers import SentenceTransformer, models\n# st_model = SentenceTransformer('/kaggle/input/sentence-transformers-222/all-MiniLM-L6-v2')\n\n# comp_path = Path('/kaggle/input/gustavosta-stable-diffusion-prompts-sd2-v2/')\n# prompts = pd.read_csv(comp_path / 'eval.csv', index_col='image_path')\n# sample_prompt_embeddings = st_model.encode(prompts['Prompt']).flatten()","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:08:31.844431Z","iopub.status.idle":"2023-04-09T06:08:31.845523Z","shell.execute_reply.started":"2023-04-09T06:08:31.845266Z","shell.execute_reply":"2023-04-09T06:08:31.845294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from scipy import spatial\n# def cosine_similarity(y_trues, y_preds):\n#     return 1 - spatial.distance.cosine(y_trues, y_preds) \n\n# sample_cos = cosine_similarity(prompt_embeddings, sample_prompt_embeddings)\n# print(sample_cos)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T06:08:31.847303Z","iopub.status.idle":"2023-04-09T06:08:31.847801Z","shell.execute_reply.started":"2023-04-09T06:08:31.847536Z","shell.execute_reply":"2023-04-09T06:08:31.84756Z"},"trusted":true},"execution_count":null,"outputs":[]}]}