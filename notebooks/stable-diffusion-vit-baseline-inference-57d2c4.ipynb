{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-20T01:24:05.164706Z","iopub.execute_input":"2023-03-20T01:24:05.165199Z","iopub.status.idle":"2023-03-20T01:24:05.172147Z","shell.execute_reply.started":"2023-03-20T01:24:05.165153Z","shell.execute_reply":"2023-03-20T01:24:05.171069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n#     model_path = '/kaggle/input/stable-diffusion-vit-baseline-train/vit_base_patch16_224.pth'\n    model_path = '/kaggle/input/swin-transformer2/swin_large_patch4_window12_384-2.pth'\n#     model_name = 'vit_base_patch16_224'\n    model_name = 'swin_large_patch4_window12_384'\n    input_size = 384\n    batch_size = 64","metadata":{"execution":{"iopub.status.busy":"2023-03-20T01:24:05.757007Z","iopub.execute_input":"2023-03-20T01:24:05.75811Z","iopub.status.idle":"2023-03-20T01:24:05.762894Z","shell.execute_reply.started":"2023-03-20T01:24:05.758065Z","shell.execute_reply":"2023-03-20T01:24:05.761854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class DiffusionTestDataset(Dataset):\n    def __init__(self, images, transform):\n        self.images = images\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.images[idx])\n        image = self.transform(image)\n        return image","metadata":{"execution":{"iopub.status.busy":"2023-03-20T01:24:09.522994Z","iopub.execute_input":"2023-03-20T01:24:09.523837Z","iopub.status.idle":"2023-03-20T01:24:09.529901Z","shell.execute_reply.started":"2023-03-20T01:24:09.523792Z","shell.execute_reply":"2023-03-20T01:24:09.528683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def predict(\n    images,\n    model_path,\n    model_name,\n    input_size,\n    batch_size\n):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    transform = transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.RandomHorizontalFlip(p=0.5),\n#         transforms.RandomRotation(degrees=10),\n\n        # transforms.RandomVerticalFlip(p=0.5),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ])\n    dataset = DiffusionTestDataset(images, transform)\n    dataloader = DataLoader(\n        dataset=dataset,\n        shuffle=False,\n        batch_size=batch_size,\n        pin_memory=True,\n        num_workers=2,\n        drop_last=False\n    )\n\n    model = timm.create_model(\n        model_name,\n        pretrained=False,\n        num_classes=384\n    )\n    \n    state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n    model.load_state_dict(state_dict)\n    model.to(device)\n    model.eval()\n    \n    tta_preds = None\n    for _ in range(2):\n        preds = []\n        for X in tqdm(dataloader, leave=False):\n            X = X.to(device)\n\n            with torch.no_grad():\n                X_out = model(X)\n                preds.append(X_out.cpu().numpy())\n                \n        if tta_preds is None:\n            tta_preds = np.vstack(preds).flatten()\n        else:\n            tta_preds += np.vstack(preds).flatten()\n    \n    return tta_preds / 2","metadata":{"execution":{"iopub.status.busy":"2023-03-20T01:24:11.655229Z","iopub.execute_input":"2023-03-20T01:24:11.65565Z","iopub.status.idle":"2023-03-20T01:24:11.668407Z","shell.execute_reply.started":"2023-03-20T01:24:11.655598Z","shell.execute_reply":"2023-03-20T01:24:11.666963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = list(Path('/kaggle/input/stable-diffusion-image-to-prompts/images').glob('*.png'))\nimgIds = [i.stem for i in images]\nEMBEDDING_LENGTH = 384\nimgId_eId = [\n    '_'.join(map(str, i)) for i in zip(\n        np.repeat(imgIds, EMBEDDING_LENGTH),\n        np.tile(range(EMBEDDING_LENGTH), len(imgIds)))]\n\nprompt_embeddings = predict(images, CFG.model_path, CFG.model_name, CFG.input_size, CFG.batch_size)\nsubmission = pd.DataFrame(\n    index=imgId_eId,\n    data=prompt_embeddings,\n    columns=['val']\n).rename_axis('imgId_eId')\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-20T01:24:12.150401Z","iopub.execute_input":"2023-03-20T01:24:12.15163Z","iopub.status.idle":"2023-03-20T01:24:57.178097Z","shell.execute_reply.started":"2023-03-20T01:24:12.151549Z","shell.execute_reply":"2023-03-20T01:24:57.176766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-20T01:25:27.119706Z","iopub.execute_input":"2023-03-20T01:25:27.120643Z","iopub.status.idle":"2023-03-20T01:25:27.132713Z","shell.execute_reply.started":"2023-03-20T01:25:27.120564Z","shell.execute_reply":"2023-03-20T01:25:27.131328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}